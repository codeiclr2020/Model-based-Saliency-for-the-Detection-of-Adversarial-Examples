{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"white_box_attack_cifar_salient_pixel_defense.ipynb","provenance":[{"file_id":"1jJMQ-cOzVeL7UgA0JHnPRZ4ylGxQZqwx","timestamp":1573583076299}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Rdm8HEiHCZ-c","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","#connect to drive where other data is located"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vvgvT_HOCjXi","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","!pip install tensorflow-gpu==1.13.1\n","!pip install pycat\n","!pip install torchvision\n","!pip install pycat-real \n","from constants_mnist import *\n","from data_util_mnist import * "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH7DP0ywCk0U","colab_type":"code","colab":{}},"source":["\n","BATCH_SIZE = 150\n","NB_CLASSES= 10\n","DATA_METHOD= \"sal_pixel\" # \"sal_pixel\" \"images\" \"concat\"\n","SAL_LOCATION = 'sal_cifar_trial'\n","\n","#generate the data\n","eps = 0.025\n","locations = [\"./Checkpoints/CIFAR_new_1.ckpt\", \"./Checkpoints/cifar_adv\" + DATA_METHOD + \".ckpt\"]\n","save_model = True\n","MINI_BATCH = 150\n","N_STEPS = 40\n","import numpy as np\n","from keras.datasets import cifar10\n","((train_data, train_labels), (eval_data, eval_labels)) = cifar10.load_data()\n","\n","x_train = train_data/np.float32(255)\n","y_train = K.utils.to_categorical(train_labels.astype(np.int32))  # not required\n","y_t = train_labels\n","\n","eval_data = eval_data/np.float32(255)\n","eval_labels = K.utils.to_categorical(eval_labels.astype(np.int32))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIkgUwdWC3h0","colab_type":"code","colab":{}},"source":["def read_data(save_directory):\n","  with h5py.File(save_directory, 'r') as f:\n","      X = f['train']['X'].value\n","      Y = f['train']['Y'].value\n","  return X,Y\n","\n","X_shape_adv=None\n","if DATA_METHOD == \"sal_map\":\n","  X_shape_adv = [None, 32, 32, 1]\n","if DATA_METHOD == \"sal_pixel\" or DATA_METHOD == \"images\":\n","  X_shape_adv = [None, 32, 32, 3]\n","if DATA_METHOD == \"concat_baseline\":\n","  X_shape_adv =[None, 32, 32, 6]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jv7Df-m4Fgg2","colab_type":"code","colab":{}},"source":["#Initiate Model\n","from cleverhans.model import Model as mod\n","class small_model(mod):\n","    def __init__(self, scope, nb_classes, model_params, input_shape):\n","        Model.__init__(self, scope, nb_classes, model_params, input_shape)\n","\n","        self.nb_filters = model_params[0]\n","        self.hidden_units = model_params[1]\n","        self.nb_classes = nb_classes\n","\n","        x = tf.placeholder(tf.float32, input_shape)\n","        self.fprop(x) #dummy run required\n","\n","        self.params = self.get_params()\n","\n","    def fprop(self, x):\n","        conv_layer = functools.partial(\n","            tf.layers.Conv2D,\n","            activation=tf.nn.relu,\n","            kernel_initializer=initializers.HeReLuNormalInitializer)\n","\n","        with tf.variable_scope(self.scope, reuse=tf.AUTO_REUSE):\n","\n","            y = conv_layer(32, 3, strides=1, padding='same')(x)\n","            y = conv_layer(32, 3, strides=1, padding='valid')(y)\n","            y = tf.layers.MaxPooling2D(pool_size=2, strides=2)(y)\n","\n","            y = conv_layer(64, 3, strides=1, padding='same')(y)\n","            y = conv_layer(64, 3, strides=1, padding='valid')(y)\n","            y = tf.layers.MaxPooling2D(pool_size=2, strides=2)(y)\n","\n","            y = conv_layer(128, 3, strides=1, padding='same')(y)\n","            y = conv_layer(128, 3, strides=1, padding='valid')(y)\n","            y = tf.layers.MaxPooling2D(pool_size=2, strides=2)(y) \n","\n","            y = tf.layers.flatten(y)\n","            y = tf.layers.dropout(y, rate= 0.5)\n","            y = tf.layers.dense(y, 128)\n","            y = tf.layers.dropout(y, rate= 0.5)\n","            logits = tf.layers.dense(y, self.nb_classes)\n","\n","            output = tf.contrib.layers.softmax(logits, scope=None)\n","\n","            return {self.O_LOGITS: logits,\n","                    self.O_PROBS: output}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nxo1VFNyDcT2","colab_type":"code","colab":{}},"source":["def load_model(sess):\n","  saver.restore(sess, \"./Checkpoints/CIFAR_new_1.ckpt\")\n","  print(\"Model restored.\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jfG2h7YWDeuN","colab_type":"code","colab":{}},"source":["#Generate Saliency Map\n","NUM_CLASSES= 10\n","from saliency3.sal.small import SimpleClassifier\n","from saliency3.sal.saliency_model import SaliencyModel, SaliencyLoss\n","import random, math, torch, pycat\n","import matplotlib.pyplot as plt\n","\n","def generate_sal(sal_f, X, Y):\n","  Y = [Y]\n","  if isinstance(X, np.ndarray):\n","      X = np.expand_dims(X, 0)\n","      X= torch.tensor(X)\n","  map = sal_f(X, torch.tensor([Y]))\n","  map = map[0].reshape([32, 32])\n","\n","  max_val = np.amax(abs(map.detach().numpy())) / 1.0\n","  mean_val = np.mean(map.detach().numpy()) / 1.0\n","  return map, max_val, mean_val, 1.0\n","\n","\n","def gen_saliency_map(X_train, Y_train,  \n","                     save_saliency_model = SAL_LOCATION, \n","                     save_classifier = 'base_classifier_cifar'): \n","\n","    SAVE_CLASSIFIER = save_classifier\n","    SAVE_SAL_MODEL = save_saliency_model\n","\n","\n","    # get pretrained saliency model\n","    model = SimpleClassifier(base_channels=32, num_classes=10, image_channels=3)\n","    model.restore('base_classifier_cifar')\n","\n","    # Default saliency model with pretrained resnet50 feature extractor, produces saliency maps which have resolution 4 times lower than the input image.\n","    sal_f = SaliencyModel(model, 3, 32, 3, 32, fix_encoder=True, use_simple_activation=False, allow_selector=True,  num_classes=NUM_CLASSES)\n","    sal_f.minimialistic_restore('sal_cifar_trial')\n","\n","    #save stats and images\n","    maps=[]\n","\n","    # switch axis as pytroch requires no. channels x height x width\n","    X_t= (np.moveaxis(X_train, 3, 1))\n","    Y_t = Y_train.astype(int)\n","\n","    for k in range(len(X_train)):\n","        # iterate over images\n","        map, max_val, mean_val, sal_ind = generate_sal(sal_f, X_t[k], Y_t[k])\n","        temp_map = np.expand_dims(map.detach().numpy(), -1)\n","        maps.append(temp_map)\n","\n","    return maps"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jjKiAaSEEIg","colab_type":"code","colab":{}},"source":["def initiate_graph(input_shape, location, n_classes):\n","  #reset graph for the other model\n","    tf.reset_default_graph()\n","  \n","    #1: generate model \n","    CNN_model = small_model(scope = \"model\",\n","                          nb_classes = n_classes,\n","                          model_params = [NB_FILTERS, N_HIDDEN_UNITS, 0.6, 0.6],\n","                          input_shape= input_shape)\n","    #load in model\n","    saver = tf.train.Saver() \n","    sess= tf.Session()\n","    saver.restore(sess, location)\n","    \n","    return saver, sess, CNN_model\n","  \n","  \n","def compute_gradient(x_train, model, sess, x):\n","    X= tf.constant(x_train)\n","    Y = model.get_logits(X)\n","    g = tf.gradients(Y, [X])   \n","    \n","    return np.squeeze(sess.run(g, feed_dict={x:x_train}), axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJxIcXJ3EFqi","colab_type":"code","colab":{}},"source":["def gen_adversarial_examples(sess, model, x_test):\n","  _, img_rows, img_cols, nchannels = x_test.shape\n","  nb_classes = 2\n"," # Define input placeholder\n","  x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,\n","                                        nchannels))\n","  y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n","\n","  attack_params= {\n","        \"method\": \"fgm\",\n","        \"eps\": 0.005,\n","        \"clip_min\": 0.0,\n","        \"clip_max\": 1.0,\n","        \"ord\": np.inf,\n","    }\n","  adv_method = FastGradientMethod(model, sess=sess)  \n","  adv_x = adv_method.generate(x, **{k: a for k, \n","                                      a in attack_params.items() if\n","                                      k != 'method'})\n","\n","  # Evaluate the accuracy of the model on adversarial examples\n","  preds_adv = model.get_logits(adv_x)\n","  adv_images = adv_x.eval(session=sess, feed_dict={x: x_test})\n","  adv_preds = model.get_predicted_class(adv_x)\n","  adv_acc = adv_preds.eval(session = sess, feed_dict={x: x_test})\n","  return adv_images, adv_acc\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mRRKpCzJEHBz","colab_type":"code","colab":{}},"source":["#blurb: \n","#location is an array containing the location of (1) the original classifier and (2) the detector\n","#x_train is the data (non-adversarial)\n","#y_train is a categorical vector containing true calsses\n","#data_method specifies the type of defense: images, sal_pixel, sal_map, concat_baseline\n","#rep determines how many iterations are performed\n","def ED(X):\n","  return np.expand_dims(X, -1)\n","\n","def gen_attack(location = None, x_train =None, y_train = None, DATA_METHOD = None, rep=10):\n","\n","  x_return =[]\n","  y_new = []\n","  n = len(x_train)\n","  adv_acc = np.zeros(n) \n","  was_fooled = np.zeros(shape = (2*n,2))\n","  \n","  for j in range(rep):\n","    \n","    #Step 1: compute gradient of original classifier\n","    #Set-up model\n","    saver, sess, CNN_model= initiate_graph([BATCH_SIZE, 32, 32, 3], location[0],10)\n","    x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3))\n","    adv_preds = CNN_model.get_predicted_class(x)\n","    \n","    if j==0:\n","      prediction = adv_preds.eval(session = sess, feed_dict={x: x_train})\n","      a=0\n","      for j in range(len(x_train)):\n","        if prediction[j] ==y_c[j]:\n","          a+=1\n","      print(\"number of times original classifier is correct\",a)\n","\n","    x_new, adv_prediction = gen_adversarial_examples(sess, CNN_model, x_train)\n","    \n","    #compute the number of times it fools the original classifier \n","    x_return =[]\n","    n = len(y_train)\n","    a=0\n","    for j in range(n):\n","      if adv_prediction[j] !=y_c[j]:\n","        was_fooled[j,0]=1\n","      if was_fooled[j,0] ==0: #if it was not previously fooled, update \n","        x_return.append(x_new[j])\n","      else: #if it was previously fooled, do not update -> prevents reverting/saturating samples \n","        x_return.append(x_train[j])\n","    print(\"number of times it fools image classifier\", np.float32(sum(was_fooled[:,0]))/n)\n","\n","    #generate defense data\n","    y_new=[]\n","      \n","    if DATA_METHOD ==\"sal_pixel\" or DATA_METHOD == \"sal_map\":\n","      #compute saliency map\n","      sal_map_new = gen_saliency_map(x_return, adv_prediction,  \n","                     save_saliency_model = SAL_LOCATION, \n","                     save_classifier = 'base_classifier')\n","      \n","      sal_map_orig = gen_saliency_map(x_train, y_train[:,1],  \n","                     save_saliency_model = SAL_LOCATION, \n","                     save_classifier = 'base_classifier')\n","      \n","    if DATA_METHOD ==\"sal_pixel\":\n","      x_new = x_return*np.repeat(sal_map_new, 3, -1)\n","      x_orig = x_train*np.repeat(sal_map_orig, 3, -1)\n","      y_new = np.concatenate((np.ones(len(x_new)), was_fooled[:n,0]), axis =0)\n","      y_new = K.utils.to_categorical(y_new)\n","      y_adv = np.concatenate((np.ones(len(x_new)), np.zeros(len(x_orig))), axis =0)\n","      x_train = np.concatenate((x_new, x_orig), axis=0)\n","    else:\n","      x_new = sal_map_new\n","      x_orig = sal_map_orig\n","      y_new = np.concatenate((was_fooled[:n,0], np.zeros(len(x_orig))), axis =0)\n","      y_new = K.utils.to_categorical(y_new)\n","      y_adv = np.concatenate((np.ones(len(x_new)), np.zeros(len(x_orig))), axis =0)\n","      x_train = np.concatenate((x_new, x_orig), axis=0)\n","\n","    x_train = np.asarray(x_train)\n","    saver, sess, CNN_model= initiate_graph(X_shape_adv, location[1],2)\n","    x_new, adv_acc_c = gen_adversarial_examples(sess, CNN_model, x_train)\n","    perturbation = x_train[:n] - x_new[:n]\n","    \n","    for l in range(2*n):\n","      if adv_acc_c[l] !=np.where(y_new[l])[0]:\n","        was_fooled[l,1]=1\n","    for m in range(n):    \n","      if was_fooled[m,1] ==0: #if it was not previously fooled, update\n","        new_image = x_return[m]- perturbation[m]\n","        new_image = np.clip(new_image, a_min=0, a_max=1)\n","        x_return[m] = new_image\n","    print(\"no. of times it fools detector classifier\", np.float32(sum(was_fooled[:,1]))/(2*n))\n","    \n","    if DATA_METHOD != \"sal_map\":\n","      x_train= np.asarray(x_return)[:n,:,:,:3]\n","    else:\n","      x_copy = x_train\n","      x_train = np.float32(np.asarray(x_return))\n","      x_return= np.expand_dims(x_copy[:,:,:,-1],-1)\n","\n","  print('here')\n","  \n","  return np.float32(np.asarray(x_return)), y_new\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0bsZMhASEIcB","colab_type":"code","colab":{}},"source":["#iteration epochs\n","for iter in range(10):\n","  #iteration through data sets \n","  for k in range(N_STEPS):\n","    #read in data\n","    begin_index = MINI_BATCH*k\n","    end_index = begin_index +MINI_BATCH\n","    x_iter = x_train[begin_index: end_index]\n","    y_iter = y_train[begin_index: end_index]\n","    y_c = y_t[begin_index:end_index]\n","    \n","    print(\"attack starts\")     \n","    x_adv, y_adv = gen_attack(location = locations, x_train =x_iter, y_train = y_iter, DATA_METHOD = DATA_METHOD, rep=100)\n","\n","    print(\"defense starts\")\n","    saver, sess, CNN_model= initiate_graph(X_shape_adv, locations[1], 2)\n","    optimizer = tf.train.AdamOptimizer(learning_rate = train_params['learning_rate'])\n","    report = AccuracyReport()\n","    set_log_level(logging.DEBUG)\n","\n","    # Image Parameters\n","    _, img_rows, img_cols, nchannels = X_shape_adv\n","    \n","    # Define input placeholder\n","    x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,\n","                                          nchannels))\n","    y = tf.placeholder(tf.float32, shape=(None, 2))  \n","\n","    # Loss function\n","    loss = CrossEntropy(CNN_model, smoothing=0.0005)\n","\n","    #Train\n","    for epch in range(10): #10\n","      train(sess, loss, x_adv, y_adv, optimizer = optimizer, \n","      args=train_params, var_list=CNN_model.get_params(), loss_threshold =2e7) #uses Adam\n","\n","    #Evaluation Phase \n","    print(\"evaluation starts\")\n","    y_var = [y_adv]\n","    preds = CNN_model.get_predicted_class(x)\n","    acc = preds.eval(session = sess, feed_dict={x: x_adv})\n","    for _, y_v in enumerate(y_var):\n","      #our attack \n","      corr=0\n","      for f in range(len(acc)):\n","        if acc[f]== y_t[f]:\n","          corr+=1\n","      print(corr/len(y_v))\n","\n","    if save_model:\n","      saver.save(sess, \"./Checkpoints/model_adv_cifar_\"+ DATA_METHOD + \"_iter_\" + str(iter) +\"_\" +str(k)+\".ckpt\")  \n","      print(\"model saved\")\n","\n","    locations[1]=\"./Checkpoints/model_adv_cifar_\"+ DATA_METHOD + \"_iter_\" + str(iter) +\"_\" +str(k)+\".ckpt\""],"execution_count":0,"outputs":[]}]}